\documentclass{article}
\usepackage{amssymb}
\usepackage{setspace}
\usepackage{csquotes}

\begin{document}

\title{Cognitive Science Final}
\author{Ozaner Hansha}
\date{December 22, 2018}
\maketitle

\doublespace

\section*{Short Answer Questions}
\subsection*{Q1}
``Motherese", or child directed speech, is characterized by exaggerated ups and downs in speech, a slower cadence, and the drawn out sounding of phonemes. It is common for caretakers in all cultures to adopt this mode of speaking when talking to their infant.

This baby talk has an important function in language learning. and so it should come as no surprise that infants show preference for this type of speech more so than regular adult talk. Talking in this way helps infants distinguish sounds that contain more important information from more filler words (like `the'), segment speech into discreet chunks (words, sentences, etc.) due to the exaggerated pauses, and even conveys the syntax of the language. Moreover, it attaches different emotions to the language based on the expression and cadence of the speaker.

These findings point to child directed speech as being an important part of the development of language in children, and that the caretakers in particular teach children to talk, at least in part, and not just nature.

\subsection*{Q2}
When an image of face is introduced to the dictator's environment, the average offer to the recipient increases. This is not just the case in the strong social cue of an actually discernable face/pair of but even a simple set of three dots (that look sort of like a face), compared to a control of three dots in a straight up triangle (doesn't look like a face).

41\% sent \$0 in the control, but when the face looking dots were introduced it dropped to 27\%. Conversely, sending an amount above \$1 went from 59\% to 73\%. These increases in generosity show the power of social cues in our decision making process.

It is important to note that this experiment (using dots) has certain advantages over the more explicit version with faces. One reason is that the subjects will not notice the blatant inclusion of the face and instead think as if they are acting of their own accord. This removes bias that results from subjects possibly understanding the experiment. Another important advantage is its simplicity. There are many other variables that come into play when considering the effect the presence of a face have on ones decisions. How big is the face, their eyes, color, etc. By using the simplest representation of a face possible (3 dots), we can minimize the amount of variables present.

Its also interesting to note that the effect of social cues (the face in this case) vary across gender. In general, females appear to not change their generosity nearly as much as males do in the presence of a face. This may seem odd at first, but it is most likely because females are more generous than males in the normal dictator game without faces present. This leads to a possible conclusion being that females don't need as much pressure from social cues (like faces) to be generous, unlike men who's decisions change quite a bit in the presence of these cues.

\subsection*{Q3}
While studying the minds of animals may seem to be more difficult than that of humans, they do share some of the same core methods and challenges. The psychological view of behaviorism holds that the valid approach to psychology is observing how humans behave in given situations rather then postulate what they are `thinking' or ask them what they thought they were thinking. The same applies to animals as we cannot say for sure whether their thoughts are even analogous to human ones. So studying the objective actions an individual (human or animal) takes can give us objectives ways to compare their psychology.

An example of this is applying the ultimatum game to a group of monkeys and to humans and comparing their results. There is no need hypothesize or measure the internal thought of each group, for their actions are what is in question. The results then show the likelihood of each group favoring the welfare of others, a property we may after the fact ascribe to the classically human notion of `fairness'.

Even further, because asking animals what they were thinking is not possible, studying the cognition of animals poses an even greater challenge than that of humans because we are limited by their expressions, actions, behaviors etc. and can't get any direct insight into their mental life (if they have one at all) like we can with other humans.

\section*{Essay Questions}
\subsection*{Q1}
\textbf{Intro}

Classically, there have been two main approaches to AI design: algorithms that use general problem solving techniques (weak methods), and algorithms that are extremely domain specific and draw heavily from current expertise in the field the problem exists in (expert systems).\\
\textbf{Weak-methods}

For example the approach of means-end analysis, very generally, is to define some goal state and apply operators to reach that goal state from the current state. What these operators were, changed from data set to data set but the underlying math was the same. This is a weak method and the overarching idea of the model being independent of the data is what distinguishes it from expert systems.\\
\textbf{Expert Systems}

Expert systems are quite the opposite of the above. Expert systems are constructed by having many experts in the field regarding the problem describe their methods for solving the problem and having programmers manually encode these rules into complex systems of checks, tests, and smaller algorithms. This is called knowledge engineering. This is the core of expert systems, to rely on past knowledge of how current professionals solve the problem rather than solve the problem in a general way. By the very nature of this approach, expert systems are highly specialized and cannot really be generalized in anyway. A new expert system for a new problem is a completely different task and must be started from scratch (unless they are very similar problems).

An example of this might be analyzing the chemical composition of exo-planets. This problem is especially apt for expert systems as there are many of them and they all require laborious work on the part of the experts. Chemists talk to the knowledge engineers and tell them what general methods they use to come to certain conclusions and then the team ask the physicist what there conclusions imply about other properties of about the planet and so on. Via complex, yet structured, lines of logic it is possible to create a program that can automatically apply the expertise of many different experts to solve a single problem.\\
\textbf{Comparison}

While in the past the amount of data and computing power available limited and ultimately made weak methods untenable, now a days it is much the opposite. Weak methods such as ANNs and the like dominate the field of AI and the expert systems of the past, which are practically impossible to maintain for problems of sufficient complexity, are not longer even considered true AI. While it was always ideal to have a general problem solving tool over a specialized one, the fact that weak methods simply could not perform practically in the real world (until relatively recently) meant that expert systems had to be developed in order to solve pressing and/or complex problems.

To the credit of expert systems, while they may be dying out, they do not require nearly as much data as weak methods do in order to function. Of course, in exchange expert system require countless hours of fine tuning and back-and-forth between the experts and the developers. An upside to this, though, is that an expert system that has a clear logical flow that can be easily understood and fixed when necessary. Weak methods, on the other hand, are just general statistical methods and so errors in their output cannot be pinpointed to a particular section.

\subsection*{Q2}
\textbf{Universal Grammar}

The existence of a universal grammar, an innate set of rules that constrain the set of all possible human languages (thereby allowing humans to acquire language so quickly) is supported the lack of positive evidence for hypothesis of language and simultaneously by the lack of reliance on negative evidence. Together these make up the poverty of stimulus argument.\\
\textbf{Lack of Positive Evidence}

When it comes to language, positive data is jus the sentence and words children are expose to. They are direct examples of language. What is interesting however is that children are able to generalize from these examples very quickly and without many of them considering all the possible different ways of generalizing them. If there was a universal grammar, this would be explainable as the space of languages that both fit the primary examples \textit{and} fit the general principles of UG is not as big as either alone.

Evidence of this is found in the fact that children only make particular kinds of overgeneralization errors and not others. In particular, children don't apply rules for kind of verb to other kinds of verbs, even if we might expect them to. No one says: ``I must coffee" or ``I hope go park''. This is what the wug test tests, it sees how children generalize imaginary words by associating them with some action/object.\\
\textbf{Non-reliance on Negative Evidence}

On the other hand, the fact that children don't get any negative examples when learning language. That is, examples of grammars that aren't part of their language. Notice that parents cannot directly correct a child's grammar instead only tell them if they gotit right or wrong as a whole. Children could not possibly generalize the correct grammar by trial and error alone, the argument goes, so there must bee some innate universal grammar that lowers the possible space of grammars.

Evidence of this can be found in mute children who have well-developed grasps of the grammar of their language, and yet they certainly aren't using negative evidence as they can't be corrected and thus learn for those corrections.

\subsection*{Q3}
The implicit false belief test, or the Sally-Anne test, is a test usually performed on young children to see if they have a working theory of mind.

In the test, two dolls named Sally and Anne are introduced to the subject. They perform a series of actions 1) Sally is shown to put a marble in a basket and then leave the stage all whilst Anne watches. 2) Once alone, Anne moves the marble form the basket to a nearby box. (note that it is only possible to tell where the marble is by looking either in the box or basket). 3) Sally now returns to look for her marble. 4) It is at this point that the tester asks the subject a question: "Where will Sally look for the marble?".

In general, 4 year olds answer correctly while 3 year olds do not. There are two primary theories on this. One is the development of a new cognitive mechanism: the selection processor. This allows the child to make executive descsiosn over their beleifs, ``This is a true beleif" and ``This is a false belief". By choosing what they beleive and don't they can 'switch' off their default bias for truth and accomplish the task.

The other explanations is that at 4 years old, children develop a theory of mind mechanism, form which they can understand others thoughts and feelings. Such a mechanism would come into existence over time and utilize cognitive mechanisms already in play for earlier in development like the shared attention mechanical, the emotion detector, eye movement detector, intention detector, etc. Combing all of these together, children can start to use different verbal and visual cues to tell what others are thinking and possibly what they could or couldn't know at a particular point in time.


\end{document}
