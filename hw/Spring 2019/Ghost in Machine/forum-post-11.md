## Forum Post 11
What model of ethics would you try to teach to an AI, and why?

I wouldn't give it a model of ethics. Whatever my purpose in building an AI, be it a toy project, a companion, a worker that needed ethics to do said work for some reason, etc. Giving it a model of ethics would be putting too much trust in this intuition we have of ethics. All 'ethics' is is a product of human society, psychology, evolution, biology, chemistry, and ultimately physics. Unless you believe in something immaterial that could possibly found morality in something cosmically objective, ethics is merely a shorthand for us (us being cobbled together evolved neural networks) to assure ourselves that our actions aren't entirely the product of cultural learning, evolved biology, and statistical noise but that we are consistent 'selves'. 'Persons' who actions are 'just' or 'good'. A hairless ape constantly doubting his self agency wouldn't be a very fit one, evolutionarily speaking.

Thus giving our idealized notions of ethics, complete with their logical holes, their plethora of edge cases, and the fact that they can only be based on nothing but arbitrary maxims, will inevitably lead to unintended behavior. Consider any one of these rules and not only will they have exceptions, but they will be founded only in a vague intuition we have: "minimize suffering in biological/sentient beings" Why? Because... pain is bad? Sort of circular. What about "never kill." Why? Because killing is... wrong? "Humans deserve freedom!" Why? "Well its a human right given to us by... nature." What the hell are you talking about? Rights? Nature? Human rights are made up ideas and 'nature' bestowing them upon us can only be metaphorical. A metaphor for our made up intuitions.

<!-- Let's consider that last rule more closely. "Don't kill." Say our robotic friend is in a situation where it must kill someone. Either by inaction or action. A trolley problem I suppose. There is no way out. Your programming of its ethics, via inclusion or exclusion, made that call. Now we enter the murky valuation of human lives and ultimately are forced to come to grips with the fact that it was all based on our, again, arbitrary intuition of right and wrong, begot from millions of years of natural selection. -->

We shouldn't kid ourselves into thinking that we have some privileged insight into some hidden objective moral reality. We are totally determined products of physics and our so called morality is nothing but a cobbled and discordant byproduct. The only reason we come up with it and respect it is because we have a propensity to, because these rules 'feel' right, not because we 'ought to'. I don't delude myself into thinking I don't do heinous things because I know the 'moral truth' (whatever that means) and others don't. It's not even because I fear retribution from society, at least not entirely. It's because I too am (entirely) a product of nature and culture who is conditioned to recoil at the thought of killing another human, eating dog meat, stealing, etc.

So if I had to program a robot with ethics, presumably to be more like humans, I wouldn't. I would just program it to be like humans, because whatever decision making process we have is certainly not this romanticized, and more importantly impossible, fantasy that is morality.

Any AI programmed to make decisions will invariably, in the lens of 'right' and 'wrong', make decisions some would consider immoral. Because, again, there was no consistent notion of moral to begin with. We only need to look at our contradictory feelings of seemingly equivalent moral situations to see this.

<!-- The easiest example of this is how we feel digested at the notion of eating the meat of animals that we domesticated as house pets rather than chattel. We like to come up with, often arbitrary or even incorrect, criterion that justifies this like "Dogs are smarter than pigs" or maybe more "emotionally intelligent" or etc. Indeed in the end the real reason was we feel closer to dogs, they're cute and pigs aren't (usually). We can do mental gymnastics all we want. -->