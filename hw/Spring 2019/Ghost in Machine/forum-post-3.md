## Forum Post 3
What questions would you use if you performed a Turing test, and why?

If I were the interrogator in a Turing test I wouldn't use questions of the following sort (this isn't exhaustive):
- Jokes or puns. This is a classic type of question to use in Turing tests but it is not impossible, nor even implausible, that we could develop a language parsing AI that could make sense of such wordplay and even analyze it for sentiment. We already have the rudiments of such systems today.
- "Is this sentence false?". This won't work either as these overplayed logical paradoxes won't 'crash the computer' or anything of the sort. A well programmed Turing test taker would be able to identify these paradoxes and simply respond with "What am I a logician?" or "the truth value of that statement is undefined" depending on what kind of person this program is trying to imitate.
- Grammatical yet incomprehensible sentences like "Colorless green ideas sleep furiously." A half-decent chatbot would probably ditch using such a grammatical model, at least partially, and learn more like a human would (that is via statistical inference networks like ANNs). Its not like we compute symbolic logic in our brains to determine whether a sentence makes sense, and so neither should an AI trying to imitate us. It would be quite thinkable to have such sentences be labeled "nonsense" by an AI trained on a large corpus of conversations, and even further have it provide a canned response like "That doesn't make any sense" or even play along with their own nonsensical statement like a human might "Yeah they do, and I bet they dream of red."
- "What is life?" or "Who made you?". Again, the program is not trying to imitate a being of perfect knowledge but just a regular old human. It should answer these big existential questions the same way you or I might. Maybe it would pause for a while and say something that sounds profound but is ultimately trite: "It's about the journey." or maybe give a frank answer like "God did, I suppose" or "natural selection I guess." It may even respond with a snarky "Nice one, that'll separate man from machine." These 'big questions' are so overplayed that they may as well come with ready made responses.
- "Write me a poem/song" or "Draw me a picture". Again we are imitating humans and considering there are AIs that can and have created better poetry, art, and music than me, I think they'll be fine. 'Creativity', as we may na√Øvely think of it, is certainly not limited to humans. It's not based on something magical or spiritual but a product of the statistical noise that is our brain, conditioned on the experiences of the other poems, art, music, etc. we have seen in the past.

<!-- Replace *brain* with *artificial neural network* and we're done. -->

<!-- One might object and say that these pieces don't have the same meaning as those created by *real* people, but to that I would counter that the 'meaning' you may find in art is totally up to interpretation and may not match what the artist thought of initially (if they even bothered to assign some meaning to it at all). Whether or not there was a 'right' answer all along certainly shouldn't make a difference as to whether something is art right? -->

While I think imitating a human is definitely possible, there may be certain questions that are harder to develop systems to answer than others. A good line of questioning may ask the program/human about their life, their career, their hopes, funny stories about themselves, etc. Not only may those things be hard for a program to generate to any detail, but making sure they are all consistent (and maybe not too consistent to account for the foggy and constructed human memory) may prove even harder.

- "What was your favorite memory from Elementary School."
- "What are your hobbies."
- [In response] "Oh really? Well tell me more about [x]."
- [Still on the topic of x] "Oh but what about [y]?"
- "When did you start getting into [x]?"
- "Hey that's kinda like how you were [x] in elementary school right?"

And so on. Ultimately AIs have yet to display decent storytelling abilities besides writing short structured pieces like news articles. Hopefully one day they can write compelling narratives on the order of Harry Potter or the like. Until then, this lacking may serve a good way to distinguish them from humans.

The problem of AIs writing stories is a massive one. Making art, poetry, songs, etc. is easy enough to conceptualize. But the fine detail and structure of the output is far more important to a story than to art (i.e. one pixel being slightly more blue doesn't matter, but a sentence that doesn't follow smoothly from another does matter). Since there is such a need for long term memory, a mastery of not just language but prose, and a understanding of why humans like different stories (i.e. data on human sentiment maybe even at the level of the brain), I don't think our current machine learning paradigm can hope to solve this problem.
