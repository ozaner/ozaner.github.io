## Forum Post 8
Which of the moral arguments for or against giving robots emotions do you find most compelling?

If by emotions we mean act and respond like a human might, expressing sadness by crying etc. then I don't see a big problem in giving robots emotions (if you accept we can do such a thing), at least as far as developing any other technology that can be manipulated to do 'bad' things. Certainly a robot that can be programmed to emote in certain ways can manipulate the emotions of other humans and thus allow you to profit off of this. But of course, this is already done by normal predatory humans, whether preying on the poor, the mourning, the destitute, or the mentally feeble. Do robots change this? Definitely, as doing it on a mass scale and with better accuracy (and thus a larger audience) is a problem. There is also the problem of how humans will perceive themselves and others as the fa√ßade of personhood is lowered just a bit further. What's distinguishes humans if all their complex feelings and processes (at least the observable ones) can and are replicated by so called mindless machines? And so, certainly, the imbuing of nonhumans with emotions should not be taken lightly.

But it would be foolish to think that not giving robots emotions is even in our power. Restricting scientific progress is extremely difficult to do, especially in the case of AI where progress is done on paper and computers and not on spaceships or particle accelerators. I personally don't think banning math equations or datasets is a great way to deal with our crumbling use of folk psychology to explain our behaviors.