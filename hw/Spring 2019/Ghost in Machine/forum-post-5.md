## Forum Post 5
What can the cockpit teach us about the future of humans and AI?

Hutchins' paper reminds us of the confusion that arises when defining, what are sometimes loaded, cognition related terms. In this case the object of this confusion is *memory*. To a functionalist, *memory* can be defined in an singular and relatively unambiguous way, where the difference between the memory of a functional system like a cockpit or computer is different to that of a human system in a known way. To a dualist, however, the kind of *memory* a human has is not only more complex or differently organized but of a whole different sort than that of any functional, non-conscious system like a computer.

If AI are ever to be considered as *beings*, however we may feel like defining that equally loaded concept, then it should seem necessary that we dispel the notion of this immaterial memory. Indeed any AI that runs on a machine is bound by physical laws. It can't go 'above and beyond its programming' as, whatever that throwaway phrase is meant to convey, all physical laws are (I imagine) completely describable via mathematics (symbol manipulation if you will) and thus computation too is a physical process. As a result, if we ever deem a computer fit to hold the title person/being/conscious, we would have to accept that the key features of that title (personhood, beinghood, consciousness, etc.) are in turn totally physical processes and 'mere symbol manipulation'.

We can get around this by positing a dual reality that separates our memory with all its redness and phenomological goodness from the simple memory of the constructed cockpit. A reality not observable nor describable via mathematical laws because if it was, then we would be able to, god forbid, explain it. And that doesn't make for a good metaphysical theory. Regardless, say we accept it. Now what? What are we even talking about if its totally unverifiable? Just ideas we like to believe are true in some sense, even if they bring us no further in explaining anything than simply stating "just because." Trusting our own intuitions doesn't make for good science (dare I say it is the antithesis of it), and basing our belief  in an immaterial memory or conscious experience that is not physical based on our unbacked feelings of how "it couldn't just be a physical process, what would separate us thinking beings from a computer?" seems absurd.